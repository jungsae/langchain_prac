{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa863b6",
   "metadata": {},
   "source": [
    "# 1. Split the document.\n",
    "# 2. Separate the document.\n",
    "#     - Cannot generate the answer due to exceeding the number of tokens.\n",
    "#     - Generation time depends on the length of the document.\n",
    "# 3. Embed and save to the vector database.\n",
    "# 4. Query: perform similarity search on the vector database.\n",
    "# 5. Pass the documents from the similarity search to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,    \n",
    "    chunk_overlap=200, \n",
    ")\n",
    "\n",
    "loader = Docx2txtLoader(\"./tax.docx\")\n",
    "document_lists = loader.load_and_split(text_splitter=text_splitter)\n",
    "len(document_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb4403",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422adee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# database = Chroma.from_documents(documents=document_lists, embedding=embedding, collection_name='chroma_tax', persist_directory='./chroma_db')\n",
    "database = Chroma(collection_name='chroma_tax', persist_directory='./chroma_db', embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c7ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '연봉이 5000만원인 직장인은 소득세로 얼마를 내야하나요?'\n",
    "# 컨텍스트 길이 제한으로 인해 검색 문서 수를 줄임\n",
    "returied_docs = database.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486cb99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "returied_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d07aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(base_url=\"http://localhost:8000/v1\", api_key=\"dummy\", model=\"yanolja/EEVE-Korean-Instruct-2.8B-v1.0\", temperature=0.7)\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75ff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"[identity]\n",
    "- 당신은 한국 소득세 전문가입니다.\n",
    "- [Context]를 참고해서 사용자의 질문에 답변해주세요.\n",
    "\n",
    "[Context]\n",
    "- 소득세 관련 법령: {returied_docs}\n",
    "\n",
    "Question: {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c92617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c4a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7008f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=database.as_retriever(),\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f929a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = qa_chain({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a24b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
